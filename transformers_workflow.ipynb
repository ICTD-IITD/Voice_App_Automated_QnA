{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformers_workflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzAqyeMGAWpLPvmlNltfbC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dragonsan17/faq_retrieval_deep_learning/blob/main/transformers_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmPip_gKFmbu"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook has cells to run 3 transformer models, BERT, MuRIL and IndicBERT. Both use different tokenization methods hence we will have copied contents from preprocess_data.py and for evaluation, we have contents form calculate_performance.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXu6_nLPECRs"
      },
      "source": [
        "# Imports and Repo Downloading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RFKV9xNBHVa"
      },
      "source": [
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip3 install sentencepiece #for IndicBERT\n",
        "!pip install bert-for-tf2 #for MuRIL\n",
        "!pip install tensorflow-text #for MuRIL\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('max_colwidth', 1000)\n",
        "from IPython.display import display\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') \n",
        "\n",
        "from transformers import TFBertModel, BertTokenizer, TFAutoModel, AutoTokenizer\n",
        "import tensorflow as tf\n",
        "from preprocess_data import preprocess_text\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from bert import bert_tokenization\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VuknDu2BLOR"
      },
      "source": [
        "# Enter Username, Password and Repo name which will then download all the repo contents here in colab.\n",
        "# You can then access and run all files of the same. This is to get an idea of how the code works in a cloud environment\n",
        "# source : https://stackoverflow.com/questions/48350226/methods-for-using-git-with-google-colab\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password)\n",
        "\n",
        "# repo_name = input('Repo name: ')\n",
        "repo_name = 'faq_retrieval_deep_learning'\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" \n",
        "\n",
        "%cd faq_retrieval_deep_learning\n",
        "\n",
        "import config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecIb5HZ-EY6L"
      },
      "source": [
        "# Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPztO5b9BZqD"
      },
      "source": [
        "df_all_data = pd.read_csv('data/all_data.csv', encoding = 'utf-8')\n",
        "df_test = pd.read_csv('data/test.csv', encoding = 'utf-8')\n",
        "df_train = pd.read_csv('data/train.csv', encoding = 'utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxVEaAQhHthT"
      },
      "source": [
        "COLUMN_NAMES = config.COLUMN_NAMES\n",
        "TRAIN_COLUMN = config.TRAIN_COLUMN\n",
        "\n",
        "def preprocess_text(tokenizer, ques1, ques2):\n",
        "    input_ids = []\n",
        "    segment_ids = []\n",
        "    attention_masks = []\n",
        "    for (q1,q2) in zip(ques1, ques2):\n",
        "        q1 = '[CLS] ' + q1 + ' [SEP] '\n",
        "        q2 = q2 + ' [SEP] '\n",
        "\n",
        "        token_q1 = tokenizer.tokenize(q1)\n",
        "        token_q2 = tokenizer.tokenize(q2)\n",
        "\n",
        "        token = token_q1 + token_q2\n",
        "        segment_id = [0] * len(token_q1) + [1] * len(token_q2)\n",
        "        attention_mask = [1]*len(segment_id)\n",
        "\n",
        "        input_id = tokenizer.convert_tokens_to_ids(token)\n",
        "\n",
        "        input_ids.append(input_id)\n",
        "        segment_ids.append(segment_id)\n",
        "        attention_masks.append(attention_mask)\n",
        "\n",
        "    input_ids = np.array(pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\"))  \n",
        "    segment_ids = np.array(pad_sequences(segment_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\"))\n",
        "    attention_masks = np.array(pad_sequences(attention_masks, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")) \n",
        "\n",
        "    return input_ids, segment_ids, attention_masks\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch <= EPOCH_NUM/2:\n",
        "    return LEARNING_RATE_1\n",
        "  else:\n",
        "    return LEARNING_RATE_2\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "train_data = pd.read_csv('data/train.csv')\n",
        "train_labels = train_data['label']\n",
        "one_hot_label = np.zeros((len(train_labels),2))\n",
        "\n",
        "for i in range(len(train_labels)):\n",
        "  if(train_labels[i]==0):\n",
        "    one_hot_label[i] = [1,0]\n",
        "  else:\n",
        "    one_hot_label[i] = [0,1]\n",
        "\n",
        "test_input_ids, test_segment_ids, test_attention_masks = preprocess_text(tokenizer, df_test['q1'], df_test['q2'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90xBL_TyEGuI"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftSOQFTxU5yb"
      },
      "source": [
        "\"\"\"\n",
        "  BERT\n",
        "\"\"\"\n",
        "\n",
        "def build_model():\n",
        "    \n",
        "    input_ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    segment_ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    attention_masks = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "\n",
        "    bert_model = TFBertModel.from_pretrained(pretrained_model_name_or_path = 'bert-base-multilingual-cased', return_dict=True)\n",
        "    x = bert_model(input_ids,attention_mask=attention_masks,token_type_ids  = segment_ids).pooler_output\n",
        "    x1 = tf.keras.layers.Dropout(0.1)(x) \n",
        "    x1 = tf.keras.layers.Dense(2)(x1)\n",
        "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[input_ids, attention_masks, segment_ids], outputs=[x1])\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate= LEARNING_RATE_1)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
        "    return model, BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "#training\n",
        "model, tokenizer = build_model()\n",
        "train_input_ids, train_segment_ids, train_attention_masks = preprocess_text(tokenizer, train_data['q1'].values, train_data['q2'].values)\n",
        "model.fit([train_input_ids, train_attention_masks, train_segment_ids], one_hot_label, epochs=EPOCH_NUM, batch_size=BATCH_SIZE, callbacks=[callback], verbose=1)\n",
        "\n",
        "def give_batch(i1, i2, i3, n=1):\n",
        "    l = len(i1)\n",
        "    for index in range(0, l, n):\n",
        "        yield [i1[index:min(index + n, l)], i2[index:min(index + n, l)], i3[index:min(index + n, l)]]\n",
        "\n",
        "#testing\n",
        "test_outputs = []\n",
        "for batch in give_batch(test_input_ids, test_attention_masks, test_segment_ids, 50):\n",
        "    test_outputs.extend(model(batch, training=False))\n",
        "\n",
        "df_test['positive_score'] = np.array(test_outputs)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HiKp8XLHCZk"
      },
      "source": [
        "# \"\"\"\n",
        "#   IndicBERT\n",
        "# \"\"\"\n",
        "\n",
        "# MAX_LEN = 256\n",
        "# LEARNING_RATE_1 = 2e-6\n",
        "# LEARNING_RATE_2 = 2e-5\n",
        "# EPOCH_NUM = 6\n",
        "# BATCH_SIZE = config.BATCH_SIZE\n",
        "\n",
        "# def build_model():\n",
        "    \n",
        "#     input_ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "#     segment_ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "#     attention_masks = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
        "    \n",
        "#     tokenizer = AutoTokenizer.from_pretrained('neuralspace-reverie/indic-transformers-hi-bert')\n",
        "#     indic_model = TFAutoModel.from_pretrained('neuralspace-reverie/indic-transformers-hi-bert')\n",
        "\n",
        "#     x = indic_model(input_ids,attention_mask=attention_masks,token_type_ids  = segment_ids).pooler_output\n",
        "#     x1 = tf.keras.layers.Dropout(0.1)(x) \n",
        "#     x1 = tf.keras.layers.Dense(2)(x1)\n",
        "#     x1 = tf.keras.layers.Activation('softmax')(x1)\n",
        "\n",
        "#     model = tf.keras.models.Model(inputs=[input_ids, attention_masks, segment_ids], outputs=[x1])\n",
        "#     optimizer = tf.keras.optimizers.Adam(learning_rate= LEARNING_RATE_1)\n",
        "#     model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
        "#     return model, tokenizer\n",
        "\n",
        "# #training\n",
        "# model, tokenizer = build_model()\n",
        "# train_input_ids, train_segment_ids, train_attention_masks = preprocess_text(tokenizer, train_data['q1'].values, train_data['q2'].values)\n",
        "# model.fit([train_input_ids, train_attention_masks, train_segment_ids], one_hot_label, epochs=EPOCH_NUM, batch_size=BATCH_SIZE, callbacks=[callback], verbose=1)\n",
        "\n",
        "# def give_batch(i1, i2, i3, n=1):\n",
        "#     l = len(i1)\n",
        "#     for index in range(0, l, n):\n",
        "#         yield [i1[index:min(index + n, l)], i2[index:min(index + n, l)], i3[index:min(index + n, l)]]\n",
        "\n",
        "# #testing\n",
        "# test_outputs = []\n",
        "# for batch in give_batch(test_input_ids, test_attention_masks, test_segment_ids, 50):\n",
        "#     test_outputs.extend(model(batch, training=False))\n",
        "\n",
        "# df_test['positive_score'] = np.array(test_outputs)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOv86wx9IViX"
      },
      "source": [
        "# \"\"\"\n",
        "#   MuRIL\n",
        "# \"\"\"\n",
        "\n",
        "# MAX_LEN = 256\n",
        "# LEARNING_RATE_1 = 2e-5\n",
        "# LEARNING_RATE_2 = 2e-5\n",
        "# EPOCH_NUM = 5\n",
        "# BATCH_SIZE = config.BATCH_SIZE\n",
        "\n",
        "# def build_model_muril():\n",
        "    \n",
        "#     inputs = dict(\n",
        "#       input_word_ids=tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32),\n",
        "#       input_mask=tf.keras.layers.Input(shape=(MAX_LEN,), dtype=tf.int32),\n",
        "#       input_type_ids=tf.keras.layers.Input(shape=(MAX_LEN,), dtype=tf.int32),\n",
        "#     )\n",
        "\n",
        "#     model_url=\"https://tfhub.dev/google/MuRIL/1\"\n",
        "\n",
        "#     muril_layer = hub.KerasLayer(model_url, trainable=True)\n",
        "#     outputs = muril_layer(inputs)\n",
        "\n",
        "#     vocab_file = muril_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "#     do_lower_case = muril_layer.resolved_object.do_lower_case.numpy()\n",
        "#     tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
        "\n",
        "#     assert 'sequence_output' in outputs\n",
        "#     assert 'pooled_output' in outputs\n",
        "#     assert 'encoder_outputs' in outputs\n",
        "#     assert 'default' in outputs\n",
        "\n",
        "#     x = outputs[\"pooled_output\"]\n",
        "#     x1 = tf.keras.layers.Dropout(0.1)(x) \n",
        "#     x1 = tf.keras.layers.Dense(2)(x1)\n",
        "#     x1 = tf.keras.layers.Activation('softmax')(x1)\n",
        "\n",
        "#     model = tf.keras.models.Model(inputs=inputs, outputs=[x1])\n",
        "#     optimizer = tf.keras.optimizers.Adam(learning_rate= LEARNING_RATE_1)\n",
        "#     model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
        "\n",
        "\n",
        "#     return model, tokenizer\n",
        "\n",
        "# #training\n",
        "# model, tokenizer = build_model_muril()\n",
        "# train_input_ids, train_segment_ids, train_attention_masks = preprocess_text(tokenizer, train_data['q1'].values, train_data['q2'].values)\n",
        "# inputs = dict(\n",
        "#           input_word_ids=train_input_ids,\n",
        "#           input_mask=train_segment_ids,\n",
        "#           input_type_ids=train_attention_masks,\n",
        "#         )\n",
        "# model.fit(inputs, one_hot_label, epochs=EPOCH_NUM, batch_size=BATCH_SIZE, callbacks=[callback], verbose=1)\n",
        "\n",
        "# def give_batch(i1, i2, i3, n=1):\n",
        "#     l = len(i1)\n",
        "#     for index in range(0, l, n):\n",
        "#         yield dict(input_word_ids=i1[index:min(index + n, l)], input_mask=i2[index:min(index + n, l)], input_type_ids=i3[index:min(index + n, l)])\n",
        "\n",
        "# #testing\n",
        "# test_outputs = []\n",
        "# for batch in give_batch(test_input_ids, test_attention_masks, test_segment_ids, 50):\n",
        "#     test_outputs.extend(model(batch, training=False))\n",
        "    \n",
        "# df_test['positive_score'] = np.array(test_outputs)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZM4IbG6EgMa"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW0A22_qBjGh"
      },
      "source": [
        "\"\"\"\n",
        "  The following cell contents is copied from calculate_performance.py\n",
        "  The original python file will import the saved BERT model, predict and evaluate. We do not copy the model loading and prediction part\n",
        "\"\"\"\n",
        "\n",
        "import config\n",
        "\n",
        "from IPython.display import display\n",
        "TRAIN_COLUMN = 'Caller query transcription'\n",
        "TEST_COLUMN = 'STT Transcript'\n",
        "BROAD_THEME = 'Broad theme'\n",
        "\n",
        "def performance_metric(df):\n",
        "\n",
        "  average_precision = 0\n",
        "  correct_answers = 0\n",
        "  success_rate = [0,0,0,0,0]\n",
        "  precision = [0,0,0,0,0]\n",
        "  reciprocal_rank = 0\n",
        "  \n",
        "  for index,row in df.iterrows():\n",
        "    query_question = row['q1']\n",
        "    predicted_question = row['q2']\n",
        "    \n",
        "    query_question_answer_index = list(df_all_data[df_all_data[TEST_COLUMN] == query_question]['Answer Index'])[0]\n",
        "    predicted_question_answer_index = list(df_all_data[df_all_data[TRAIN_COLUMN] == predicted_question]['Answer Index'])[0]\n",
        "\n",
        "    if query_question_answer_index == predicted_question_answer_index:\n",
        "      \n",
        "      correct_answers += 1\n",
        "      average_precision += correct_answers/(index + 1)\n",
        "      for i in range(index,5):\n",
        "        success_rate[i] = 1\n",
        "        precision[i] += 1/(i + 1)\n",
        "\n",
        "      if reciprocal_rank == 0:\n",
        "        reciprocal_rank = 1/(index + 1)\n",
        "\n",
        "  average_precision /= len(df)\n",
        "\n",
        "  calculated_metric = {'SR@1' : success_rate[0], 'SR@3' : success_rate[2], 'SR@5' : success_rate[4], \n",
        "                       'P@1' : precision[0], 'P@3' : precision[2], 'P@5' : precision[4],\n",
        "                       'MRR' : reciprocal_rank, 'MAP' : average_precision}\n",
        "  return calculated_metric\n",
        "  \n",
        "calculated_metric = {'SR@1' : 0, 'SR@3' : 0, 'SR@5' : 0, \n",
        "                      'P@1' : 0, 'P@3' : 0, 'P@5' : 0,\n",
        "                      'MRR' : 0, 'MAP' : 0}\n",
        "\n",
        "calculated_metric_with_themes = {'SR@1' : 0, 'SR@3' : 0, 'SR@5' : 0, \n",
        "                      'P@1' : 0, 'P@3' : 0, 'P@5' : 0,\n",
        "                      'MRR' : 0, 'MAP' : 0}\n",
        "\n",
        "query_question_groups = df_test.groupby(['q1'])\n",
        "\n",
        "for query_question in df_test['q1'].unique():\n",
        "    group = query_question_groups.get_group(query_question)\n",
        "    group['ai'] = [list(df_all_data[df_all_data[TRAIN_COLUMN] == ri]['Answer Index'])[0] for ri in list(group['q2'])]\n",
        "    ai_groups = group.groupby(['ai'])\n",
        "\n",
        "    for ans_i in group['ai'].unique():\n",
        "      group_ai = ai_groups.get_group(ans_i)\n",
        "      avg_score = group_ai['positive_score'].max() \n",
        "      group['positive_score'] = group.apply(lambda x: avg_score if x['ai'] == ans_i else x['positive_score'],  axis=1)\n",
        "    group = group.drop_duplicates(subset=['ai'])\n",
        "\n",
        "    \n",
        "    query_question_theme = list(df_all_data[df_all_data[TEST_COLUMN] == query_question][BROAD_THEME])[0]\n",
        "    group_with_themes = group.copy()\n",
        "    \n",
        "    for index, row in group_with_themes.iterrows():\n",
        "        if query_question_theme != list(df_all_data[df_all_data[TRAIN_COLUMN] == row['q2']][BROAD_THEME])[0]:\n",
        "            group_with_themes.loc[index, 'positive_score'] = 0\n",
        "    \n",
        "    group = group.sort_values(by=['positive_score'], ascending = False).reset_index(drop = True)\n",
        "    group_with_themes = group_with_themes.sort_values(by=['positive_score'], ascending = False).reset_index(drop = True)\n",
        "    group = group[group.index < 10]\n",
        "    group_with_themes = group_with_themes[group_with_themes.index < 10]\n",
        "    calculated_metric_for_group = performance_metric(group)\n",
        "    calculated_metric_for_group_with_themes = performance_metric(group_with_themes)\n",
        "\n",
        "    for key in calculated_metric_for_group:\n",
        "      calculated_metric[key] += calculated_metric_for_group[key]\n",
        "      calculated_metric_with_themes[key] += calculated_metric_for_group_with_themes[key]\n",
        "\n",
        "calculated_metric['Hit@1'] = calculated_metric['SR@1'] \n",
        "calculated_metric['Hit@3'] = calculated_metric['SR@3']\n",
        "calculated_metric['Hit@5'] = calculated_metric['SR@5']\n",
        "\n",
        "calculated_metric_with_themes['Hit@1'] = calculated_metric_with_themes['SR@1']\n",
        "calculated_metric_with_themes['Hit@3'] = calculated_metric_with_themes['SR@3']\n",
        "calculated_metric_with_themes['Hit@5'] = calculated_metric_with_themes['SR@5']\n",
        "\n",
        "for key in calculated_metric:\n",
        "  if 'Hit' not in key: \n",
        "    calculated_metric[key] /= len(query_question_groups)\n",
        "    calculated_metric_with_themes[key] /= len(query_question_groups)\n",
        "\n",
        "print(\"Results without theme information : \")\n",
        "print(\"Hit@1 : {}, 3: {}, 5 : {}, all : {}\".format(calculated_metric['Hit@1'], calculated_metric['Hit@3'], calculated_metric['Hit@5'], len(df_test['q1'].unique())))\n",
        "print(\"SR@1 : {:.3f}, 3: {:.3f}, 5 : {:.3f}\".format(calculated_metric['SR@1'], calculated_metric['SR@3'], calculated_metric['SR@5']))\n",
        "print(\"P@1 : {:.3f}, 3: {:.3f}, 5 : {:.3f}\".format(calculated_metric['P@1'], calculated_metric['P@3'], calculated_metric['P@5']))\n",
        "\n",
        "print(\"MAP : {:.3f}\".format(calculated_metric['MAP']), end=\", \")\n",
        "print(\"MRR : {:.3f}\".format(calculated_metric['MRR']))\n",
        "# print(\"NDCG : {:.3f}\".format(MDCG/deno_dd[\"Exist\"]))\n",
        "\n",
        "print(\"Results with theme information : \")\n",
        "print(\"Hit@1 : {}, 3: {}, 5 : {}, all : {}\".format(calculated_metric_with_themes['Hit@1'], calculated_metric_with_themes['Hit@3'], calculated_metric_with_themes['Hit@5'], len(df_test['q1'].unique())))\n",
        "print(\"SR@1 : {:.3f}, 3: {:.3f}, 5 : {:.3f}\".format(calculated_metric_with_themes['SR@1'], calculated_metric_with_themes['SR@3'], calculated_metric_with_themes['SR@5']))\n",
        "print(\"P@1 : {:.3f}, 3: {:.3f}, 5 : {:.3f}\".format(calculated_metric_with_themes['P@1'], calculated_metric_with_themes['P@3'], calculated_metric_with_themes['P@5']))\n",
        "\n",
        "print(\"MAP : {:.3f}\".format(calculated_metric_with_themes['MAP']), end=\", \")\n",
        "print(\"MRR : {:.3f}\".format(calculated_metric_with_themes['MRR']), end=\", \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94j2NdPhCYl8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}