{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jaccard_model_workflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJN9bai/V2nZn9eFgGAt87",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dragonsan17/faq_retrieval_deep_learning/blob/main/jaccard_model_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXu6_nLPECRs"
      },
      "source": [
        "# Imports and Repo Downloading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RFKV9xNBHVa"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('max_colwidth', 1000)\n",
        "from IPython.display import display\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VuknDu2BLOR"
      },
      "source": [
        "# Enter Username, Password and Repo name which will then download all the repo contents here in colab.\n",
        "# You can then access and run all files of the same. This is to get an idea of how the code works in a cloud environment\n",
        "# source : https://stackoverflow.com/questions/48350226/methods-for-using-git-with-google-colab\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password)\n",
        "\n",
        "# repo_name = input('Repo name: ')\n",
        "repo_name = 'faq_retrieval_deep_learning'\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" \n",
        "\n",
        "%cd faq_retrieval_deep_learning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90xBL_TyEGuI"
      },
      "source": [
        "# Jaccard and Weighted Jaccard Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_JqKjxCCHqf"
      },
      "source": [
        "# hindi_stopwords = [\"अंदर\",\"अत\",\"अदि\",\"अप\",\"अपना\",\"अपनि\",\"अपनी\",\"अपने\",\"अभि\",\"अभी\",\"आदि\",\"आप\",\"इंहिं\",\"इंहें\",\"इंहों\",\"इतयादि\",\"इत्यादि\",\"इन\",\"इनका\",\"इन्हीं\",\"इन्हें\",\"इन्हों\",\"इस\",\"इसका\",\"इसकि\",\"इसकी\",\"इसके\",\"इसमें\",\"इसि\",\"इसी\",\"इसे\",\"उंहिं\",\"उंहें\",\"उंहों\",\"उन\",\"उनका\",\"उनकि\",\"उनकी\",\"उनके\",\"उनको\",\"उन्हीं\",\"उन्हें\",\"उन्हों\",\"उस\",\"उसके\",\"उसि\",\"उसी\",\"उसे\",\"एक\",\"एवं\",\"एस\",\"एसे\",\"ऐसे\",\"ओर\",\"और\",\"कइ\",\"कई\",\"कर\",\"करता\",\"करते\",\"करना\",\"करने\",\"करें\",\"कहते\",\"कहा\",\"का\",\"काफि\",\"काफ़ी\",\"कि\",\"किंहें\",\"किंहों\",\"कितना\",\"किन्हें\",\"किन्हों\",\"किया\",\"किर\",\"किस\",\"किसि\",\"किसी\",\"किसे\",\"की\",\"कुछ\",\"कुल\",\"के\",\"को\",\"कोइ\",\"कोई\",\"कोन\",\"कोनसा\",\"कौन\",\"कौनसा\",\"गया\",\"घर\",\"जब\",\"जहाँ\",\"जहां\",\"जा\",\"जिंहें\",\"जिंहों\",\"जितना\",\"जिधर\",\"जिन\",\"जिन्हें\",\"जिन्हों\",\"जिस\",\"जिसे\",\"जीधर\",\"जेसा\",\"जेसे\",\"जैसा\",\"जैसे\",\"जो\",\"तक\",\"तब\",\"तरह\",\"तिंहें\",\"तिंहों\",\"तिन\",\"तिन्हें\",\"तिन्हों\",\"तिस\",\"तिसे\",\"तो\",\"था\",\"थि\",\"थी\",\"थे\",\"दबारा\",\"दवारा\",\"दिया\",\"दुसरा\",\"दुसरे\",\"दूसरे\",\"दो\",\"द्वारा\",\"न\",\"नहिं\",\"नहीं\",\"ना\",\"निचे\",\"निहायत\",\"नीचे\",\"ने\",\"पर\",\"पहले\",\"पुरा\",\"पूरा\",\"पे\",\"फिर\",\"बनि\",\"बनी\",\"बहि\",\"बही\",\"बहुत\",\"बाद\",\"बाला\",\"बिलकुल\",\"भि\",\"भितर\",\"भी\",\"भीतर\",\"मगर\",\"मानो\",\"मे\",\"में\",\"यदि\",\"यह\",\"यहाँ\",\"यहां\",\"यहि\",\"यही\",\"या\",\"यिह\",\"ये\",\"रखें\",\"रवासा\",\"रहा\",\"रहे\",\"ऱ्वासा\",\"लिए\",\"लिये\",\"लेकिन\",\"व\",\"वगेरह\",\"वरग\",\"वर्ग\",\"वह\",\"वहाँ\",\"वहां\",\"वहिं\",\"वहीं\",\"वाले\",\"वुह\",\"वे\",\"वग़ैरह\",\"संग\",\"सकता\",\"सकते\",\"सबसे\",\"सभि\",\"सभी\",\"साथ\",\"साबुत\",\"साभ\",\"सारा\",\"से\",\"सो\",\"हि\",\"ही\",\"हुअ\",\"हुआ\",\"हुइ\",\"हुई\",\"हुए\",\"हे\",\"हें\",\"है\",\"हैं\",\"हो\",\"होता\",\"होति\",\"होती\",\"होते\",\"होना\",\"होने\",\"मैं\",\"मुझको\",\"मेरा\",\"अपने\",\"आप को\",\"हमने\",\"हमारा\",\"अपना\",\"हम\",\"आप\",\"आपका\",\"तुम्हारा\",\"अपने\",\"आप\",\"स्वयं\",\"वह\",\"इसे\",\"उसके\",\"खुद\",\"को\",\"कि\",\"वह\",\"उसकी\",\"उसका\",\"खुद\",\"ही\",\"यह\",\"इसके\",\"उन्होने\",\"अपने\",\"क्या\",\"जो\",\"किसे\",\"किसको\",\"कि\",\"ये\",\"हूँ\",\"होता\",\"है\",\"रहे\",\"थी\",\"थे\",\"होना\",\"गया\",\"किया\",\"जा रहा है\",\"किया\",\"है\",\"है\",\"पडा\",\"होने\",\"करना\",\"करता\",\"है\",\"किया\",\"रही\",\"एक\",\"लेकिन\",\"अगर\",\"या\",\"क्यूंकि\",\"जैसा\",\"जब\",\"तक\",\"जबकि\",\"की\",\"पर\",\"द्वारा\",\"के\",\"लिए\",\"साथ\",\"के\",\"बारे\",\"में\",\"खिलाफ\",\"बीच\",\"में\",\"के\",\"माध्यम\",\"से\",\"दौरान\",\"से\",\"पहले\",\"के\",\"बाद\",\"ऊपर\",\"नीचे\",\"को\",\"से\",\"तक\",\"से\",\"नीचे\",\"करने\",\"में\",\"निकल\",\"बंद\",\"से\",\"अधिक\",\"तहत\",\"दुबारा\",\"आगे\",\"फिर\",\"एक\",\"बार\",\"यहाँ\",\"वहाँ\",\"कब\",\"कहाँ\",\"क्यों\",\"कैसे\",\"सारे\",\"किसी\",\"दोनो\",\"प्रत्येक\",\"ज्यादा\",\"अधिकांश\",\"अन्य\",\"में\",\"कुछ\",\"ऐसा\",\"में\",\"कोई\",\"मात्र\",\"खुद\",\"समान\",\"इसलिए\",\"बहुत\",\"सकता\",\"जायेंगे\",\"जरा\",\"चाहिए\",\"अभी\",\"और\",\"कर\",\"दिया\",\"रखें\",\"का\",\"हैं\",\"इस\",\"होता\",\"करने\",\"ने\",\"बनी\",\"तो\",\"ही\",\"हो\",\"इसका\",\"था\",\"हुआ\",\"वाले\",\"बाद\",\"लिए\",\"सकते\",\"इसमें\",\"दो\",\"वे\",\"करते\",\"कहा\",\"वर्ग\",\"कई\",\"करें\",\"होती\",\"अपनी\",\"उनके\",\"यदि\",\"हुई\",\"जा\",\"कहते\",\"जब\",\"होते\",\"कोई\",\"हुए\",\"व\",\"जैसे\",\"सभी\",\"करता\",\"उनकी\",\"तरह\",\"उस\",\"आदि\",\"इसकी\",\"उनका\",\"इसी\",\"पे\",\"तथा\",\"भी\",\"परंतु\",\"इन\",\"कम\",\"दूर\",\"पूरे\",\"गये\",\"तुम\",\"मै\",\"यहां\",\"हुये\",\"कभी\",\"अथवा\",\"गयी\",\"प्रति\",\"जाता\",\"इन्हें\",\"गई\",\"अब\",\"जिसमें\",\"लिया\",\"बड़ा\",\"जाती\",\"तब\",\"उसे\",\"जाते\",\"लेकर\",\"बड़े\",\"दूसरे\",\"जाने\",\"बाहर\",\"स्थान\",\"उन्हें\",\"गए\",\"ऐसे\",\"जिससे\",\"समय\",\"दोनों\",\"किए\",\"रहती\",\"इनके\",\"इनका\",\"इनकी\",\"सकती\",\"आज\",\"कल\",\"जिन्हें\",\"जिन्हों\",\"तिन्हें\",\"तिन्हों\",\"किन्हों\",\"किन्हें\",\"इत्यादि\",\"इन्हों\",\"उन्हों\",\"बिलकुल\",\"निहायत\",\"इन्हीं\",\"उन्हीं\",\"जितना\",\"दूसरा\",\"कितना\",\"साबुत\",\"वग़ैरह\",\"कौनसा\",\"लिये\",\"दिया\",\"जिसे\",\"तिसे\",\"काफ़ी\",\"पहले\",\"बाला\",\"मानो\",\"अंदर\",\"भीतर\",\"पूरा\",\"सारा\",\"उनको\",\"वहीं\",\"जहाँ\",\"जीधर\",\"﻿के\",\"एवं\",\"कुछ\",\"कुल\",\"रहा\",\"जिस\",\"जिन\",\"तिस\",\"तिन\",\"कौन\",\"किस\",\"संग\",\"यही\",\"बही\",\"उसी\",\"मगर\",\"कर\",\"मे\",\"एस\",\"उन\",\"सो\",\"अत\"]\n",
        "hindi_stopwords = [] #Not removing stopwords is giving better results currently"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tj9a6jlhBOTZ"
      },
      "source": [
        "\"\"\"\n",
        "  Helper Functions for Jaccard Model\n",
        "\"\"\"\n",
        "\n",
        "def get_jaccard_sim(str1, str2, sw, weights = None): \n",
        "\n",
        "  if weights == None:\n",
        "    str1 = str(str1).split()\n",
        "    str2 = str(str2).split()\n",
        "    str1 = ' '.join([w for w in str1 if not w in sw])\n",
        "    str2 = ' '.join([w for w in str2 if not w in sw])   \n",
        "    a = set(str1.split()) \n",
        "    b = set(str2.split())\n",
        "    c = a.intersection(b)\n",
        "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
        "  else:\n",
        "    str1 = str(str1).split()\n",
        "    str2 = str(str2).split()\n",
        "    str1 = ' '.join([w for w in str1 if not w in sw])\n",
        "    str2 = ' '.join([w for w in str2 if not w in sw])   \n",
        "    a = set(str1.split()) \n",
        "    b = set(str2.split())\n",
        "    c = a.intersection(b)\n",
        "\n",
        "    a_w = 0\n",
        "    b_w = 0\n",
        "    c_w = 0\n",
        "\n",
        "    for word in list(a):\n",
        "      if word in weights:\n",
        "        a_w += weights[word]\n",
        "    for word in list(b):\n",
        "      if word in weights:\n",
        "        b_w += weights[word]\n",
        "    for word in list(c):\n",
        "      if word in weights:\n",
        "        c_w += weights[word]\n",
        "    return c_w / max(a_w + b_w - c_w, 1)\n",
        "\n",
        "\n",
        "def jaccard_model(test_q1, test_q2, sw):\n",
        "  predictions = []\n",
        "\n",
        "  for i in range(len(test_q1)):\n",
        "    q1 = test_q1[i]\n",
        "    q2 = test_q2[i]\n",
        "    score = get_jaccard_sim(q1,q2, sw)\n",
        "    predictions.append(score)\n",
        "\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdL9ACuiBWhT"
      },
      "source": [
        "#Reference: https://towardsdatascience.com/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n",
        "\"\"\"\n",
        "  Helper Functions for Weighted Jaccard Model\n",
        "\"\"\"\n",
        "def computeTF(wordDict, bagOfWords):\n",
        "    tfDict = {}\n",
        "    bagOfWordsCount = len(bagOfWords)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count / float(bagOfWordsCount)\n",
        "    return tfDict\n",
        "\n",
        "def computeIDF(unique_words, documents):\n",
        "    import math\n",
        "    N = len(documents)\n",
        "    \n",
        "    idfDict = dict.fromkeys(unique_words, 0)\n",
        "    for document in documents:\n",
        "        for word in document:\n",
        "            idfDict[word] += 1\n",
        "    \n",
        "    for word, val in idfDict.items():\n",
        "\n",
        "        idfDict[word] = math.log(N / float(val))\n",
        "    return idfDict\n",
        "\n",
        "def computeTFIDF(tfBagOfWords, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBagOfWords.items():\n",
        "        tfidf[word] = val * idfs[word]\n",
        "    return tfidf\n",
        "    \n",
        "def weighted_jaccard(df_train, df_test, stopwords):\n",
        "  \n",
        "  labels = list(set(list(df_train['t1']) + list(df_train['t2'])))\n",
        "  \n",
        "  documents = []\n",
        "  for lab in labels:\n",
        "    s = ''\n",
        "    for i,r in df_train.iterrows():\n",
        "      if r['t1'] == lab:\n",
        "        s+= r['q1']\n",
        "        s+=' '\n",
        "      if r['t2'] == lab:\n",
        "        s+= r['q2']\n",
        "        s+=' '\n",
        "    documents.append(s)\n",
        "  train_text = documents\n",
        "  print(len(documents))\n",
        "\n",
        "  bag_of_words = []\n",
        "  unique_words = set([])\n",
        "  for document in documents:\n",
        "    new_words = set(document.split())\n",
        "    unique_words = unique_words.union(new_words)\n",
        "    bag_of_words.append(new_words)\n",
        "\n",
        "  unique_words.discard(set(stopwords))\n",
        "  num_words_all = []\n",
        "\n",
        "  for i in range(len(bag_of_words)):\n",
        "    num_words = dict.fromkeys(unique_words, 0)\n",
        "    for word in documents[i].split():\n",
        "      num_words[word] += 1\n",
        "    num_words_all.append(num_words)\n",
        "    \n",
        "\n",
        "  idf = computeIDF(unique_words, bag_of_words)\n",
        "\n",
        "  all_tfidf = []\n",
        "  for i in range(len(bag_of_words)):\n",
        "    tf = computeTF(num_words_all[i], bag_of_words[i])\n",
        "    tfidf = computeTFIDF(tf, idf)\n",
        "    all_tfidf.append(tfidf)\n",
        "\n",
        "  df = pd.DataFrame(all_tfidf)\n",
        "\n",
        "  test_q1 = df_test['q1']\n",
        "  test_q2 = df_test['q2']\n",
        "  predictions = []\n",
        "  for i in range(len(test_q1)):\n",
        "    for j in range(len(labels)):\n",
        "      if labels[j] == df_test['t1'][i]:\n",
        "\n",
        "        q1 = test_q1[i]\n",
        "        q2 = test_q2[i]\n",
        "        weights = all_tfidf[j]\n",
        "        score = get_jaccard_sim(q1,q2, stopwords, weights)\n",
        "        predictions.append(score)\n",
        "        break\n",
        "\n",
        "  print(\"Words with highest Tf-Idf weights theme-wise:\")\n",
        "  for i in range(len(labels)):\n",
        "    print(\"Theme: \", labels[i])\n",
        "    d = Counter(all_tfidf[i])\n",
        "    print(\"Words: \",d.most_common(50))\n",
        "\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecIb5HZ-EY6L"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPztO5b9BZqD"
      },
      "source": [
        "df_all_data = pd.read_csv('data/all_data.csv', encoding = 'utf-8')\n",
        "df_test = pd.read_csv('data/test.csv', encoding = 'utf-8')\n",
        "df_train = pd.read_csv('data/train.csv', encoding = 'utf-8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZM4IbG6EgMa"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMcsZfaSBaY2"
      },
      "source": [
        "#Jaccard Model\n",
        "df_test['positive_score'] = jaccard_model(df_test['q1'], df_test['q2'], hindi_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn_CgeghCWCq"
      },
      "source": [
        "#Weighted Jaccard Model\n",
        "\n",
        "# df_train['t1'] = [(list(df_all_data[df_all_data['STT Transcript'] == q]['Broad theme']) + list(df_all_data[df_all_data['Caller query transcription'] == q]['Broad theme']))[0] for q in list(df_train['q1']) ]\n",
        "# df_train['t2'] = [(list(df_all_data[df_all_data['STT Transcript'] == q]['Broad theme']) + list(df_all_data[df_all_data['Caller query transcription'] == q]['Broad theme']))[0] for q in list(df_train['q2']) ]\n",
        "# df_test['t1'] = [(list(df_all_data[df_all_data['STT Transcript'] == q]['Broad theme']) + list(df_all_data[df_all_data['Caller query transcription'] == q]['Broad theme']))[0] for q in list(df_test['q1']) ]\n",
        "# df_test['t2'] = [(list(df_all_data[df_all_data['STT Transcript'] == q]['Broad theme']) + list(df_all_data[df_all_data['Caller query transcription'] == q]['Broad theme']))[0] for q in list(df_test['q2']) ]\n",
        "# df_test['positive_score'] = weighted_jaccard(df_train, df_test, hindi_stopwords)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW0A22_qBjGh"
      },
      "source": [
        "def performance_metric(df):\n",
        "\n",
        "  average_precision = 0\n",
        "  correct_answers = 0\n",
        "  success_rate = [0,0,0,0,0]\n",
        "  precision = [0,0,0,0,0]\n",
        "  reciprocal_rank = 0\n",
        "  \n",
        "  for index,row in df.iterrows():\n",
        "    query_question = row['q1']\n",
        "    predicted_question = row['q2']\n",
        "    \n",
        "    query_question_answer_index = list(df_all_data[df_all_data[TEST_COLUMN] == query_question]['Answer Index'])[0]\n",
        "    predicted_question_answer_index = list(df_all_data[df_all_data[TRAIN_COLUMN] == predicted_question]['Answer Index'])[0]\n",
        "\n",
        "    if query_question_answer_index == predicted_question_answer_index:\n",
        "      \n",
        "      correct_answers += 1\n",
        "      average_precision += correct_answers/(index + 1)\n",
        "      for i in range(index,5):\n",
        "        success_rate[i] = 1\n",
        "        precision[i] += 1/(i + 1)\n",
        "\n",
        "      if reciprocal_rank == 0:\n",
        "        reciprocal_rank = 1/(index + 1)\n",
        "\n",
        "  average_precision /= len(df)\n",
        "\n",
        "  calculated_metric = {'SR@1' : success_rate[0], 'SR@3' : success_rate[2], 'SR@5' : success_rate[4], \n",
        "                       'P@1' : precision[0], 'P@3' : precision[2], 'P@5' : precision[4],\n",
        "                       'MRR' : reciprocal_rank, 'MAP' : average_precision}\n",
        "  return calculated_metric\n",
        "  \n",
        "calculated_metric = {'SR@1' : 0, 'SR@3' : 0, 'SR@5' : 0, \n",
        "                      'P@1' : 0, 'P@3' : 0, 'P@5' : 0,\n",
        "                      'MRR' : 0, 'MAP' : 0}\n",
        "\n",
        "calculated_metric_with_themes = {'SR@1' : 0, 'SR@3' : 0, 'SR@5' : 0, \n",
        "                      'P@1' : 0, 'P@3' : 0, 'P@5' : 0,\n",
        "                      'MRR' : 0, 'MAP' : 0}\n",
        "\n",
        "query_question_groups = df_test.groupby(['q1'])\n",
        "\n",
        "for query_question in df_test['q1'].unique():\n",
        "    group = query_question_groups.get_group(query_question)\n",
        "    group['ai'] = [list(df_all_data[df_all_data[TRAIN_COLUMN] == ri]['Answer Index'])[0] for ri in list(group['q2'])]\n",
        "    ai_groups = group.groupby(['ai'])\n",
        "\n",
        "    for ans_i in group['ai'].unique():\n",
        "      group_ai = ai_groups.get_group(ans_i)\n",
        "      avg_score = group_ai['positive_score'].max() \n",
        "      group['positive_score'] = group.apply(lambda x: avg_score if x['ai'] == ans_i else x['positive_score'],  axis=1)\n",
        "    group = group.drop_duplicates(subset=['ai'])\n",
        "\n",
        "    \n",
        "    query_question_theme = list(df_all_data[df_all_data[TEST_COLUMN] == query_question][BROAD_THEME])[0]\n",
        "    group_with_themes = group.copy()\n",
        "    \n",
        "    for index, row in group_with_themes.iterrows():\n",
        "        if query_question_theme != list(df_all_data[df_all_data[TRAIN_COLUMN] == row['q2']][BROAD_THEME])[0]:\n",
        "            group_with_themes.loc[index, 'positive_score'] = 0\n",
        "    \n",
        "    group = group.sort_values(by=['positive_score'], ascending = False).reset_index(drop = True)\n",
        "    group_with_themes = group_with_themes.sort_values(by=['positive_score'], ascending = False).reset_index(drop = True)\n",
        "    group = group[group.index < 10]\n",
        "    group_with_themes = group_with_themes[group_with_themes.index < 10]\n",
        "    calculated_metric_for_group = performance_metric(group)\n",
        "    calculated_metric_for_group_with_themes = performance_metric(group_with_themes)\n",
        "\n",
        "    for key in calculated_metric_for_group:\n",
        "      calculated_metric[key] += calculated_metric_for_group[key]\n",
        "      calculated_metric_with_themes[key] += calculated_metric_for_group_with_themes[key]\n",
        "\n",
        "calculated_metric['Hit@1'] = calculated_metric['SR@1'] \n",
        "calculated_metric['Hit@3'] = calculated_metric['SR@3']\n",
        "calculated_metric['Hit@5'] = calculated_metric['SR@5']\n",
        "\n",
        "calculated_metric_with_themes['Hit@1'] = calculated_metric_with_themes['SR@1']\n",
        "calculated_metric_with_themes['Hit@3'] = calculated_metric_with_themes['SR@3']\n",
        "calculated_metric_with_themes['Hit@5'] = calculated_metric_with_themes['SR@5']\n",
        "\n",
        "for key in calculated_metric:\n",
        "  if 'Hit' not in key: \n",
        "    calculated_metric[key] /= len(query_question_groups)\n",
        "    calculated_metric_with_themes[key] /= len(query_question_groups)\n",
        "\n",
        "print(\"Results without theme information : \")\n",
        "print(\"Hit@1 : {}, 3: {}, 5 : {}, all : {}\".format(calculated_metric['Hit@1'], calculated_metric['Hit@3'], calculated_metric['Hit@5'], len(df_test['q1'].unique())))\n",
        "print(\"SR@1 : {:.3f}, 3: {:.3f}, 5 : {:.3f}\".format(calculated_metric['SR@1'], calculated_metric['SR@3'], calculated_metric['SR@5']))\n",
        "print(\"P@1 : {:.3f}, 3: {:.3f}, 5 : {:.3f}\".format(calculated_metric['P@1'], calculated_metric['P@3'], calculated_metric['P@5']))\n",
        "\n",
        "print(\"MAP : {:.3f}\".format(calculated_metric['MAP']), end=\", \")\n",
        "print(\"MRR : {:.3f}\".format(calculated_metric['MRR']))\n",
        "# print(\"NDCG : {:.3f}\".format(MDCG/deno_dd[\"Exist\"]))\n",
        "\n",
        "print(\"Results with theme information : \")\n",
        "print(\"Hit@1 : {}, 3: {}, 5 : {}, all : {}\".format(calculated_metric_with_themes['Hit@1'], calculated_metric_with_themes['Hit@3'], calculated_metric_with_themes['Hit@5'], len(df_test['q1'].unique())))\n",
        "print(\"SR@1 : {:.3f}, 3: {:.3f}, 5 : {:.3f}\".format(calculated_metric_with_themes['SR@1'], calculated_metric_with_themes['SR@3'], calculated_metric_with_themes['SR@5']))\n",
        "print(\"P@1 : {:.3f}, 3: {:.3f}, 5 : {:.3f}\".format(calculated_metric_with_themes['P@1'], calculated_metric_with_themes['P@3'], calculated_metric_with_themes['P@5']))\n",
        "\n",
        "print(\"MAP : {:.3f}\".format(calculated_metric_with_themes['MAP']), end=\", \")\n",
        "print(\"MRR : {:.3f}\".format(calculated_metric_with_themes['MRR']), end=\", \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94j2NdPhCYl8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}